# 쿠버네티스에서의 GPU 자원 관리 (vLLM 활용) - 추후 학습 진행 예정

쿠버네티스에서 GPU 노드를 운영할 때, GPU 자원을 효율적으로 관리하여 활용도를 최대화하고 단일 프로세스가 GPU를 독점하는 것을 방지하는 것이 중요합니다. 특히 vLLM과 Kubeflow를 사용할 때 효율적인 GPU 자원 관리를 위한 여러 가지 전략을 소개합니다.

## 1. GPU 메모리 분할 (멀티 테넌시)
- **MIG (Multi-Instance GPU)**: NVIDIA GPU는 MIG(Multi-Instance GPU)라는 기능을 지원하여, 하나의 GPU를 여러 개의 작은 가상 GPU로 나눌 수 있습니다. 각 인스턴스는 서로 다른 프로세스나 사용자가 독립적으로 사용할 수 있습니다.
  - 예를 들어, NVIDIA A100 GPU는 최대 7개의 MIG 인스턴스로 나눌 수 있어 여러 사용자나 프로세스에 GPU 자원을 효율적으로 할당할 수 있습니다.

## 2. GPU 쿼터 및 리소스 제한
- 쿠버네티스에서는 파드에 GPU 자원을 할당할 때 리소스 제한을 설정하여 특정 프로세스가 모든 GPU 자원을 독점하지 않도록 할 수 있습니다.
  - YAML 구성 예시:
    ```yaml
    resources:
      limits:
        nvidia.com/gpu: 1
    ```
  - 이러한 제한을 설정함으로써 여러 파드가 GPU 자원을 공유할 수 있으며, 하나의 파드가 자원을 독점하는 것을 방지할 수 있습니다.

## 3. 작업 스케줄러 활용
- **Kubeflow Pipelines** 및 **Kube-batch**를 사용하여 GPU 자원 할당을 최적화할 수 있습니다. `Kube-batch`는 작업을 배치 방식으로 스케줄링하여 높은 우선순위의 작업이 먼저 처리되고 자원이 효율적으로 사용되도록 합니다.
- **Ray**와 같은 분산 컴퓨팅 프레임워크를 사용하면 클러스터 내 작업을 분산 처리하고, 각 작업이 GPU를 효율적으로 할당받도록 도와줍니다.

## 4. 자동 스케일링 및 GPU 클러스터링
- **자동 스케일링**: 동적 자동 스케일링을 사용하여 GPU 자원 요구에 따라 클러스터 크기를 조정할 수 있습니다. **Kubeflow**의 `KFServing`을 통해 머신 러닝 모델 서빙 시 GPU 자원을 자동으로 스케일링할 수 있습니다.
- **Horovod**와 **TensorFlow Serving**: 이러한 프레임워크를 사용하면 모델 학습이나 추론 시 여러 프로세스가 GPU 자원을 공유하여 GPU 활용도를 극대화할 수 있습니다.

## 5. 샤딩 (데이터 및 모델 샤딩)
- **데이터 샤딩**: 데이터를 여러 파티션으로 나누고 각 파티션을 개별 GPU가 처리하도록 하면 여러 GPU를 동시에 활용할 수 있습니다.
- **모델 샤딩**: 모델을 여러 GPU에 걸쳐 나눠서 학습하거나 추론하는 것도 효과적입니다. **TensorFlow**와 **PyTorch**는 모두 여러 GPU에서 모델을 병렬 처리하는 기능을 제공합니다.

## 6. GPU 활용도 모니터링 및 동적 스케줄링
- **NVIDIA DCGM (Data Center GPU Manager)**을 사용하여 GPU 자원 사용률을 모니터링할 수 있습니다. 이 정보를 바탕으로 GPU가 충분히 활용되지 않을 경우 새로운 작업을 동적으로 스케줄링할 수 있습니다.
- 쿠버네티스에서는 이러한 모니터링 데이터를 활용하여 GPU 자원이 유휴 상태일 때 자동으로 새로운 작업을 할당하여 GPU 활용도를 높일 수 있습니다.

## 7. 특정 노드에서 GPU 사용 설정 (Kubeflow 연동)
쿠버네티스 클러스터에서 특정 노드에만 GPU가 있을 경우, 해당 노드에 `gpu_label=true` 라는 라벨을 추가하여 GPU 자원이 있는 노드에만 파드가 스케줄링되도록 설정할 수 있습니다. 이를 Kubeflow Pipeline에서 활용하여 GPU 자원이 있는 노드에만 파드를 배포하려면 아래와 같이 노드 셀렉터 및 톨러레이션을 설정해야 합니다.